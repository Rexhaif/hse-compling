{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/zhivago.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.9M\n",
      "-rw-r--r-- 1 root root  778 Nov  8 20:08 Assignment.ipynb\n",
      "-rw-r--r-- 1 root root 1.9M Nov  8 20:08 zhivago.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import razdel\n",
    "import nltk\n",
    "import rusenttokenize\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./zhivago.txt\", 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 - Очистка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "## удаляем xml-like теги\n",
    "_text = re.sub('(\\<(/?[^>]+)>)', ' ', text)\n",
    "## строки из логов загрузчика\n",
    "_text = re.sub('\\d{2}.\\d{2}.\\d{4}', '', _text)\n",
    "_text = re.sub('[^\\S]*\\.(ru)\\S*', '', _text)\n",
    "_text = re.sub('\\d{1}.\\d{1}', '', _text)\n",
    "## Цифры, Латиницу(логи загрузчика), скобочки(ибо зачем)\n",
    "_text = re.sub('[0-9a-zA-Z«»]', '', _text)\n",
    "## Странные штуки в конце\n",
    "_text = re.sub(\"[/+]\", '', _text)\n",
    "## -\n",
    "_text = re.sub('\\s–\\s', '', _text)\n",
    "## лишние пробелы\n",
    "text = re.sub(\"\\s+\", ' ', _text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2 - токенизация/разделение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = \"\".join((set(string.punctuation) - set(\".\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.translate(str.maketrans('', '', punctuation)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = rusenttokenize.ru_sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fda3e88eb944b7485ab898307e4c968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11812.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Приводим к нижнему регистру после токенизации, т.к отсутствие регистра может повлиять на корректность токенизации\n",
    "tokenized_sentences = [\n",
    "    tuple(token.text.lower() for token in razdel.tokenize(sentence)) for sentence in tqdm(sentences)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Повторяющиеся предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeating_sentences = list(map(\n",
    "    lambda x: (\" \".join(x[0]), x[1]), # детокенизируем для отображения\n",
    "    filter(\n",
    "        lambda x: x[1] >= 2 and x[0][0] != '–', # встречающиеся два и более раз, не являющиеся прямой речью (начинается с -)\n",
    "        counter.most_common()\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторяющиеся предложения есть, всего их(без учета прямой речи) -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "print(len(repeating_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры таких предложений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('да .', 10),\n",
       " ('сеялки .', 4),\n",
       " ('но дело не в этом .', 3),\n",
       " ('молотилки .', 3),\n",
       " ('свеча горела на столе свеча горела .', 3),\n",
       " ('единственно живое и яркое в васэто то что вы жили в одно время со мной и меня знали .',\n",
       "  2),\n",
       " ('весной в несколько дней лес преображается подымается до облаков в его покрытых листьями дебрях можно затеряться спрятаться .',\n",
       "  2),\n",
       " ('это превращение достигается движением по стремительности превосходящим движения животных потому что животное не растет так быстро как растение и которого никогда нельзя подсмотреть .',\n",
       "  2),\n",
       " ('лес не передвигается мы не можем его накрыть подстеречь за переменою места .',\n",
       "  2),\n",
       " ('мы всегда застаем его в неподвижности .', 2)]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeating_sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Самый частотный токен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = Counter()\n",
    "for sentence in tokenized_sentences:\n",
    "    frequencies.update(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent = list(filter(lambda x: len(x[0]) > 6, frequencies.most_common()))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самый частотный токен длинее 6 символов - андреевич, он встречается 285 раз\n"
     ]
    }
   ],
   "source": [
    "print(f\"Самый частотный токен длинее 6 символов - {most_frequent[0]}, он встречается {most_frequent[1]} раз\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Стемминг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = list([word for sentence in tokenized_sentences for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = list(map(stemmer.stem, all_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Слово не изменилось после стеммизации\n",
    "Если интерпретировать такую ошибку как сказано в условии - то таких ошибок очень много"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e76048cd2c43b8bb08c7907e5107b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=164145.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## ошибки не-стеммизации\n",
    "non_stemmed_idx = list(filter(lambda x: len(x[1]) > 4 and x[1] == stemmed_words[x[0]], enumerate(tqdm(all_words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6661"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_stemmed_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако я думаю что большинство из них не представляют собой действительно ошибки, просто слово является само себе \"стеммой\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  |       борис         ==        борис        \n",
      "  1  |     леонидович      ==      леонидович     \n",
      "  2  |     пастернак       ==      пастернак      \n",
      "  3  |       доктор        ==        доктор       \n",
      "  5  |       доктор        ==        доктор       \n",
      " 18  |       принес        ==        принес       \n",
      " 45  |       доктор        ==        доктор       \n",
      " 63  |      человек        ==       человек       \n",
      " 66  |       пишет         ==        пишет        \n",
      " 107 |       жертв         ==        жертв        \n",
      " 114 |       перед         ==        перед        \n",
      " 136 |       строк         ==        строк        \n",
      " 140 |       могут         ==        могут        \n",
      " 162 |       борис         ==        борис        \n",
      " 163 |     пастернак       ==      пастернак      \n",
      " 164 |       доктор        ==        доктор       \n",
      " 167 |       дышат         ==        дышат        \n",
      " 177 |       доктор        ==        доктор       \n",
      " 179 |       борис         ==        борис        \n",
      " 180 |     пастернак       ==      пастернак      \n",
      " 192 |       перед         ==        перед        \n",
      " 215 |       период        ==        период       \n",
      " 223 |      покамест       ==       покамест      \n",
      " 238 |       будет         ==        будет        \n",
      " 250 |     подскажет       ==      подскажет      \n",
      " 253 |       чисел         ==        чисел        \n",
      " 257 |       сейчас        ==        сейчас       \n",
      " 260 |       будет         ==        будет        \n",
      " 269 |       будут         ==        будут        \n",
      " 297 |       конец         ==        конец        \n"
     ]
    }
   ],
   "source": [
    "for i, w in non_stemmed_idx[:30]:\n",
    "    print(f\"{i:^5}|{all_words[i]:^20} == {stemmed_words[i]:^20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но и ошибки тоже есть, см. слова #260 и #269 - две словоформы одной лексемы (\"будет\"), и они не изменились после стеммирования, хотя нужно было бы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Одна стемма для разных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem2words = {}\n",
    "for i, word in enumerate(all_words):\n",
    "    stemm = stemmed_words[i]\n",
    "    if stemm not in stem2words:\n",
    "        stem2words[stemm] = set()\n",
    "        \n",
    "    stem2words[stemm].add(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем смотреть такие слова, длина формы которых очень сильно отличается от длины стеммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "error_pairs = {}\n",
    "for key, forms in stem2words.items():\n",
    "    if len(key) <= 6 and np.mean([abs(len(key) - len(form)) for form in forms]) >= 5 and len(forms) > 2:\n",
    "        error_pairs[key] = forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('оста',\n",
       "  {'оставшегося',\n",
       "   'оставшееся',\n",
       "   'оставшейся',\n",
       "   'оставшеюся',\n",
       "   'оставшиеся',\n",
       "   'оставшимися',\n",
       "   'оставшимся',\n",
       "   'оставшись',\n",
       "   'оставшихся',\n",
       "   'оставшуюся',\n",
       "   'остаемся',\n",
       "   'остается',\n",
       "   'осталась',\n",
       "   'остались',\n",
       "   'осталось',\n",
       "   'остался',\n",
       "   'остаться',\n",
       "   'остаются',\n",
       "   'остающееся',\n",
       "   'остающемся',\n",
       "   'остающимися',\n",
       "   'остающимся'}),\n",
       " ('сохран',\n",
       "  {'сохрани',\n",
       "   'сохранив',\n",
       "   'сохранившая',\n",
       "   'сохранившаяся',\n",
       "   'сохранившегося',\n",
       "   'сохранившейся',\n",
       "   'сохранившиеся',\n",
       "   'сохранившимся',\n",
       "   'сохранившихся',\n",
       "   'сохранились',\n",
       "   'сохранилось',\n",
       "   'сохранился',\n",
       "   'сохранить',\n",
       "   'сохранности',\n",
       "   'сохранны'}),\n",
       " ('выс', {'выси', 'высившаяся', 'высившейся', 'высившуюся', 'высилась'}),\n",
       " ('появ',\n",
       "  {'появившаяся',\n",
       "   'появилась',\n",
       "   'появились',\n",
       "   'появилось',\n",
       "   'появился',\n",
       "   'появиться'}),\n",
       " ('прокат', {'прокатившегося', 'прокатились', 'прокатился', 'прокатиться'}),\n",
       " ('заблуд',\n",
       "  {'заблудившаяся',\n",
       "   'заблудившиеся',\n",
       "   'заблудившийся',\n",
       "   'заблудился',\n",
       "   'заблудитесь',\n",
       "   'заблудиться'}),\n",
       " ('почуд', {'почудились', 'почудилось', 'почудиться'}),\n",
       " ('свал',\n",
       "  {'свалившаяся',\n",
       "   'свалившемся',\n",
       "   'свалившемуся',\n",
       "   'свалившись',\n",
       "   'свалила',\n",
       "   'свалились',\n",
       "   'свалилось',\n",
       "   'свалился',\n",
       "   'свалит',\n",
       "   'свалиться'}),\n",
       " ('каса',\n",
       "  {'касавшиеся',\n",
       "   'касавшихся',\n",
       "   'касается',\n",
       "   'касалось',\n",
       "   'касался',\n",
       "   'касаться',\n",
       "   'касающееся',\n",
       "   'касающемся',\n",
       "   'касающиеся',\n",
       "   'касающуюся'}),\n",
       " ('лопа', {'лопались', 'лопаться', 'лопающейся', 'лопающиеся'}),\n",
       " ('очут',\n",
       "  {'очутившаяся',\n",
       "   'очутилась',\n",
       "   'очутились',\n",
       "   'очутилось',\n",
       "   'очутился',\n",
       "   'очутиться'}),\n",
       " ('пузыр', {'пузырившегося', 'пузырились', 'пузырями'}),\n",
       " ('покос',\n",
       "  {'покосившаяся', 'покосившиеся', 'покосившихся', 'покосился', 'покоситься'}),\n",
       " ('девян', {'девяносто', 'девяностого', 'девяностый'}),\n",
       " ('светя', {'светящиеся', 'светящимися', 'светящимся'}),\n",
       " ('улыба',\n",
       "  {'улыбавшийся',\n",
       "   'улыбалась',\n",
       "   'улыбались',\n",
       "   'улыбаться',\n",
       "   'улыбающаяся',\n",
       "   'улыбающегося'}),\n",
       " ('обязан', {'обязанностей', 'обязанности', 'обязанность'}),\n",
       " ('ют', {'ютившейся', 'ютились', 'ютилось'}),\n",
       " ('числен', {'численности', 'численность', 'численностью'}),\n",
       " ('яв', {'явившегося', 'явилась', 'явился', 'явится', 'явиться'}),\n",
       " ('отзыва', {'отзывавшимся', 'отзываетесь', 'отзывалась'}),\n",
       " ('разраз', {'разразившегося', 'разразившись', 'разразилась'})]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(error_pairs.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди таких слов можно найти несколько примеров ошибок, удовлетворяющих условию\n",
    "- 'пузыр': пузырившегося(деепричастие?) и пузырями(сущ.)\n",
    "- 'выси': выси(сущ.) и высившаяся(деепричастие?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - список стоп-слов из nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на самые частотные слова в нашем тексте, которые не встречаются в stopwords и посмотрим какие из них можно туда добавить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = {k:v for k, v in frequencies.most_common(200)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'это', 'время', 'поезд', 'тебе', 'андреевич', 'люди', 'доктор', 'жизни', 'своим', 'доме', 'которых', 'наверное', 'глаза', 'дома', 'точно', 'которой', 'вместе', 'стали', 'кроме', 'дом', 'сама', 'доктора', 'эта', 'всем', 'человек', 'часть', 'правда', 'нам', 'знаю', '...', 'словно', 'друг', 'ночь', 'очень', 'юрия', 'юрий', 'чтото', '.', 'день', 'нем', 'живаго', 'стало', 'окна', 'говорит', 'времени', 'кругом', 'оно', 'этим', 'лара', 'свете', 'который', 'андреевича', 'этих', 'юра', 'руки', 'которые', 'пока', 'своей', 'стал', 'ними', 'несколько', 'голову', 'дело', 'своих', 'жизнь', 'минуту', 'конца', 'сторону', 'весь'}\n"
     ]
    }
   ],
   "source": [
    "dissset = set(freq_words.keys()) - set(stop_words)\n",
    "print(dissset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первые четыре слов, которые можно добавить в стоп-слова - это вариации слова 'это': \n",
    "- это\n",
    "- эта\n",
    "- этим\n",
    "- этих\n",
    "\n",
    "Почему:\n",
    "1. В стоп словах уже есть несколько вариаций слова 'это': этот, этого, этом, эти, эту, этой. Поэтому, следуя той же логике, можно добавить отсутствующие вариации, которые мы видим в нашем тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['этот', 'этого', 'этом', 'эти', 'эту', 'этой']"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x.startswith('э'), stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Они очень часто встречаются в тексте, например 'это' встречается 1001 раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "949"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words['это']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пятое слово - это 'оно'\n",
    "\n",
    "Почему его стоит добавить в список стоп-слов: в списке уже есть аналогичные слова для м.р, ж.р, и мн. числа. Выглядит как ошибка, что в списке нет формы для среднего рода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['он', 'она', 'они']"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x.startswith('он'), stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5 - лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem()\n",
    "pymorhy = MorphAnalyzer()\n",
    "vocab = list(set(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f73881742843868d7a750af91287d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mystem_lemms = list(map(lambda x: mystem.lemmatize(x)[0], tqdm(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a81b55874442f585d6cc16f457e0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pymorphy_lemms = list(map(lambda x: pymorhy.normal_forms(x)[0], tqdm(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch = [\n",
    "    (frequencies[vocab[i]], vocab[i], mystem_lemms[i], pymorphy_lemms[i]) \n",
    "    for i in range(len(vocab)) \n",
    "    if (mystem_lemms[i] != pymorphy_lemms[i])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch = sorted(mismatch, key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|# occurs|    word     |   mystem3    |   pymorphy2   |\n",
      "-------------------------------------------------------\n",
      "|  753   |     все     |     все      |      всё      |\n",
      "|  349   |     еще     |     еще      |      ещё      |\n",
      "|  234   |     со      |      со      |       с       |\n",
      "|  206   |     во      |      во      |       в       |\n",
      "|  202   |     чем     |     что      |      чем      |\n",
      "|  161   |     ним     |      он      |      они      |\n",
      "|  161   |    может    |    может     |     мочь      |\n",
      "|  141   |   больше    |    больше    |    большой    |\n",
      "|  132   |    того     |      то      |      тот      |\n",
      "|  122   |    чтото    |    чтото     |     чтоть     |\n",
      "|  114   |    есть     |     быть     |     есть      |\n",
      "|  114   |    всех     |     все      |     весь      |\n",
      "|  108   |     тем     |      то      |      тем      |\n",
      "|  103   |    стал     | становиться  |     стать     |\n",
      "|   97   |    всем     |     все      |     весь      |\n",
      "|   94   |    дома     |     дома     |      дом      |\n",
      "|   88   |     об      |      об      |       о       |\n",
      "|   83   |    стало    | становиться  |     стать     |\n",
      "|   76   |     том     |     том      |      тот      |\n",
      "|   72   |    всего    |    всего     |     весь      |\n",
      "|   67   |    стали    | становиться  |     стать     |\n",
      "|   62   |    свете    |    света     |     свет      |\n",
      "|   62   |    лучше    |    хорошо    |    хороший    |\n",
      "|   59   |   дальше    |    далеко    |    далёкий    |\n",
      "|   52   |  чтонибудь  |  чтонибудь   |   чтонибыть   |\n",
      "|   47   |   кажется   |   кажется    |   казаться    |\n",
      "|   45   |    стала    | становиться  |     стать     |\n",
      "|   43   |  федоровна  |  федоровна   |   фёдорович   |\n",
      "|   43   |   какойто   |   какойто    |   какойтый    |\n",
      "|   42   |    всеми    |     все      |     весь      |\n",
      "|   41   |    ночью    |     ночь     |     ночью     |\n",
      "|   37   |   вперед    |    вперед    |    вперёд     |\n",
      "|   37   |   раньше    |     рано     |    ранний     |\n",
      "|   37   |    свое     |     свое     |     свой      |\n",
      "|   36   |    изза     |     изза     |      изз      |\n",
      "|   36   |    всему    |     все      |     весь      |\n",
      "|   36   |    тому     |      то      |      тот      |\n",
      "|   35   |    гдето    |    гдето     |     гдеть     |\n",
      "|   30   |александровна|александровна | александрович |\n",
      "|   30   |  антонина   |   антонина   |    антонин    |\n",
      "|   29   |    этому    |     это      |     этот      |\n",
      "|   29   |     ко      |      ко      |       к       |\n",
      "|   29   |   когдато   |   когдатый   |    когдато    |\n",
      "|   29   |   скорее    |    скоро     |    скорее     |\n",
      "|   29   |    вышел    |   выходить   |     выйти     |\n",
      "|   28   |   антипов   |   антипов    |     антип     |\n",
      "|   28   |   отчего    |    отчего    |     отчий     |\n",
      "|   28   |  антипова   |   антипова   |    антипов    |\n",
      "|   28   |    лары     |     лары     |     лара      |\n",
      "|   28   |    ктото    |    ктото     |     ктоть     |\n"
     ]
    }
   ],
   "source": [
    "print(\"|# occurs|    word     |   mystem3    |   pymorphy2   |\")\n",
    "print(\"-------------------------------------------------------\")\n",
    "for count, vocab, lemma_mystem, lemma_pymorphy in mismatch[:50]:\n",
    "    print(f\"|{count:^8}|{vocab:^13}|{lemma_mystem:^14}|{lemma_pymorphy:^15}|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из результатов анализа мисматчей для наиболее частотных слов, видно, что каждая библиотека имеет свои проблемы:\n",
    "1. Pymorphy2 подвержен Gender Bias: имена/отчества/фамилии в ж.р нормализуются в аналогичные, но в м.р. \n",
    "\n",
    "Mystem так не ошибается, скорее всего из-за того что у него словарь меньшего размера и он обрабатывает такие слова как ошибки\n",
    "\n",
    "2. Mystem некорректно лемматизирует некоторые устаревшие формы предлогов, см. 'ко', 'об', 'со', 'во'.\n",
    "3. Pymorphy2 исправляет ошибки в ходе лемматизации слов, которые должны быть написаны через 'ё', но написаны с 'е', см. вперед, еще, все(вероятно)\n",
    "4. Иногда это исправление некорректно, см. дальше. В т.ч исправления ошибок другого типа тоже могут быть некорректны, см. ктото, изза, гдето, какойто, чтото. В тоже время Mystem не делает ничего с словами, написанными с ошибкой.\n",
    "\n",
    "В итоге можно сказать, что для анализа текстов такого рода больше подходит mystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
