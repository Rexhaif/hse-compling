{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import pandas as pd\n",
    "from rich import print, progress\n",
    "from gensim.models import Word2Vec, FastText, KeyedVectors\n",
    "from string import punctuation\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "punct = punctuation+'«»—…“”*№–'\n",
    "stops = set(stopwords.words('russian'))\n",
    "m = Mystem()\n",
    "\n",
    "mapping = {\n",
    "     'A': 'ADJ',\n",
    "     'ADV': 'ADV',\n",
    "     'ADVPRO': 'ADV',\n",
    "     'ANUM': 'ADJ',\n",
    "     'APRO': 'DET',\n",
    "     'COM': 'ADJ',\n",
    "     'CONJ': 'SCONJ',\n",
    "     'INTJ': 'INTJ',\n",
    "     'NONLEX': 'X',\n",
    "     'NUM': 'NUM',\n",
    "     'PART': 'PART',\n",
    "     'PR': 'ADP',\n",
    "     'S': 'NOUN',\n",
    "     'SPRO': 'PRON',\n",
    "     'UNKN': 'X',\n",
    "     'V': 'VERB'\n",
    "}\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    \n",
    "    words = [word.strip(punct) for word in text.lower().split()]\n",
    "    words = [morph.parse(word)[0].normal_form for word in words if word and word not in stops]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "def tokenize(text):\n",
    "    \n",
    "    \n",
    "    tokens = [token.text for token in list(razdel_tokenize(text))]\n",
    "    tokens = [token for token in tokens if token.isalnum()]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def normalize_mystem(text):\n",
    "    tokens = []\n",
    "    norm_words = m.analyze(text)\n",
    "    for norm_word in norm_words:\n",
    "        if 'analysis' not in norm_word:\n",
    "            continue\n",
    "            \n",
    "        if not len(norm_word['analysis']):\n",
    "            lemma = norm_word['text']\n",
    "            pos = 'UNKN'\n",
    "        else:\n",
    "            lemma = norm_word[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "            pos = norm_word[\"analysis\"][0][\"gr\"].split(',')[0]\n",
    "            pos = pos.split('=')[0].strip()\n",
    "        pos = mapping[pos]\n",
    "        tokens.append(lemma+'_'+pos)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"paraphrases.xml\", 'rb') as f:\n",
    "    corpus_xml = html.fromstring(open('paraphrases.xml', 'rb').read())\n",
    "    texts_1 = []\n",
    "    texts_2 = []\n",
    "    classes = []\n",
    "\n",
    "    for p in corpus_xml.xpath('//paraphrase'):\n",
    "        texts_1.append(p.xpath('./value[@name=\"text_1\"]/text()')[0])\n",
    "        texts_2.append(p.xpath('./value[@name=\"text_2\"]/text()')[0])\n",
    "        classes.append(p.xpath('./value[@name=\"class\"]/text()')[0])\n",
    "\n",
    "    data = pd.DataFrame({'text_1':texts_1, 'text_2':texts_2, 'label':classes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2957\n",
       "-1    2582\n",
       "1     1688\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание №1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-12 08:44:50--  https://rexhaif.keybase.pub/ru-uk-bg_tweets.parquet?dl=1\n",
      "Resolving rexhaif.keybase.pub (rexhaif.keybase.pub)... 52.1.81.129, 34.192.29.4, 34.204.113.10\n",
      "Connecting to rexhaif.keybase.pub (rexhaif.keybase.pub)|52.1.81.129|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 489016724 (466M) [application/octet-stream]\n",
      "Saving to: ‘ru-uk-bg_tweets.parquet?dl=1’\n",
      "\n",
      "ru-uk-bg_tweets.par 100%[===================>] 466.36M  1.32MB/s    in 6m 13s  \n",
      "\n",
      "2021-02-12 08:51:04 (1.25 MB/s) - ‘ru-uk-bg_tweets.parquet?dl=1’ saved [489016724/489016724]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# попробуем учить эмбеддинги на дампе киррилических твитов (русский/украинский/болгарский)\n",
    "!wget https://rexhaif.keybase.pub/ru-uk-bg_tweets.parquet?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ru-uk-bg_tweets.parquet\\?dl\\=1 ru-uk-bg_tweets.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_parquet(\"ru-uk-bg_tweets.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ru    4187232\n",
       "uk     294097\n",
       "bg      60794\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.lang.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c77fe2a057e40f5b5224ae7551429f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4542123.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for text in tqdm(corpus['text']):\n",
    "    if \"RT\" not in text:\n",
    "        text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)\n",
    "        text = text.replace(\"\\n\", \" \").replace(\"\\xa0\", \" \").strip()\n",
    "        texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae05a05e61bc40eeace216d4137a8ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3344176.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "norm_tweets = [normalize(tokenize(text)) for text in tqdm(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000\">'фотография сделать телефон выглядеть неземной ангел чонгук'</span>,\n",
       "    <span style=\"color: #008000\">'вместе навсегда семь самый крепкий голливудский пара голливудский пара удаваться хранить</span>\n",
       "<span style=\"color: #008000\">любовь спустя десятигод'</span>,\n",
       "    <span style=\"color: #008000\">'быть человек просить любить bts помочь набрать'</span>,\n",
       "    <span style=\"color: #008000\">'чушь собачий макаревич откреститься концерт кремль'</span>,\n",
       "    <span style=\"color: #008000\">'сколько'</span>,\n",
       "    <span style=\"color: #008000\">'злой отнять ачивка жодить семь смертный грех хотя посмотреть'</span>,\n",
       "    <span style=\"color: #008000\">'дело гражданство реально идиотка'</span>,\n",
       "    <span style=\"color: #008000\">'такой забота домашний'</span>,\n",
       "    <span style=\"color: #008000\">'отдыхать загорать молодец респект бля работать сидеть работать лох который деньга'</span>,\n",
       "    <span style=\"color: #008000\">'лола практически случиться'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efdfd8c1bb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(norm_tweets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec([text.split() for text in norm_tweets], size=300, sg=1, workers=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fst = FastText([text.split() for text in norm_tweets], sg=1, size=300, workers=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'чимин'</span>, <span style=\"color: #000080; font-weight: bold\">0.8211683034896851</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'юнга'</span>, <span style=\"color: #000080; font-weight: bold\">0.8206780552864075</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'тэхен'</span>, <span style=\"color: #000080; font-weight: bold\">0.8104677200317383</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'хосока'</span>, <span style=\"color: #000080; font-weight: bold\">0.7999343276023865</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'тэхить'</span>, <span style=\"color: #000080; font-weight: bold\">0.778852641582489</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'намджуна'</span>, <span style=\"color: #000080; font-weight: bold\">0.7768256664276123</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'джина'</span>, <span style=\"color: #000080; font-weight: bold\">0.7635465264320374</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'чон'</span>, <span style=\"color: #000080; font-weight: bold\">0.7352989912033081</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'тэхёный'</span>, <span style=\"color: #000080; font-weight: bold\">0.7215493321418762</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'сокджина'</span>, <span style=\"color: #000080; font-weight: bold\">0.7197335958480835</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7eff1c306760>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(w2v.wv.most_similar(\"чонгук\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'чонгукк'</span>, <span style=\"color: #000080; font-weight: bold\">0.9606845378875732</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'чонгуг'</span>, <span style=\"color: #000080; font-weight: bold\">0.9170444011688232</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'чонгукер'</span>, <span style=\"color: #000080; font-weight: bold\">0.9013263583183289</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'нгук'</span>, <span style=\"color: #000080; font-weight: bold\">0.8908102512359619</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'чонгуков'</span>, <span style=\"color: #000080; font-weight: bold\">0.8820027709007263</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'ёнгук'</span>, <span style=\"color: #000080; font-weight: bold\">0.8759435415267944</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'чонг'</span>, <span style=\"color: #000080; font-weight: bold\">0.8559625148773193</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'чонгуууук'</span>, <span style=\"color: #000080; font-weight: bold\">0.8548625707626343</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'чонгучек'</span>, <span style=\"color: #000080; font-weight: bold\">0.8482362031936646</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000\">'енгук'</span>, <span style=\"color: #000080; font-weight: bold\">0.8438962697982788</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efac3a6cc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(fst.wv.most_similar(\"чонгук\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качетсве ещё одинх эмбеддингов используем tayga_upos_skipgram_300_2_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://vectors.nlpl.eu/repository/20/185.zip && unzip 185.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_rusvec = KeyedVectors.load_word2vec_format(\"model.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model, dim):\n",
    "    text = text.split()\n",
    "    \n",
    "    # чтобы не доставать одно слово несколько раз\n",
    "    # сделаем счетчик, а потом векторы домножим на частоту\n",
    "    words = Counter(text)\n",
    "    total = len(text)\n",
    "    vectors = np.zeros((len(words), dim))\n",
    "    \n",
    "    for i,word in enumerate(words):\n",
    "        try:\n",
    "            v = model[word]\n",
    "            vectors[i] = v*(words[word]/total) # просто умножаем вектор на частоту\n",
    "        except (KeyError, ValueError):\n",
    "            continue\n",
    "    \n",
    "    if vectors.any():\n",
    "        vector = np.average(vectors, axis=0)\n",
    "    else:\n",
    "        vector = np.zeros((dim))\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edfb7ac051945bb96f437107fd5cea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-fa32f3af3c2d>:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  v = model[word]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_own, X_rusvec = [], []\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data['label'])\n",
    "for row in tqdm(data.itertuples()):\n",
    "    x1_own = get_embedding(normalize(tokenize(row.text_1)), w2v, 300)\n",
    "    x2_own = get_embedding(normalize(tokenize(row.text_2)), w2v, 300)\n",
    "    X_own.append(\n",
    "        np.concatenate([\n",
    "            x1_own,\n",
    "            x2_own,\n",
    "            np.maximum(x1_own, x2_own),\n",
    "            np.add(x1_own, x2_own),\n",
    "            np.subtract(x1_own, x2_own)\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    x1_rusvec = get_embedding(\" \".join(normalize_mystem(row.text_1)), w2v_rusvec, 300)\n",
    "    x2_rusvec = get_embedding(\" \".join(normalize_mystem(row.text_2)), w2v_rusvec, 300)\n",
    "    X_rusvec.append(\n",
    "        np.concatenate([\n",
    "            x1_rusvec,\n",
    "            x2_rusvec,\n",
    "            np.maximum(x1_rusvec, x2_rusvec),\n",
    "            np.add(x1_rusvec, x2_rusvec),\n",
    "            np.subtract(x1_rusvec, x2_rusvec)\n",
    "        ])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_own = np.stack(X_own)\n",
    "X_rusvec = np.stack(X_rusvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold - <span style=\"color: #000080; font-weight: bold\">0</span>| f-score: <span style=\"color: #000080; font-weight: bold\">0.6844</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efb544de280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold - <span style=\"color: #000080; font-weight: bold\">1</span>| f-score: <span style=\"color: #000080; font-weight: bold\">0.6873</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efb544ded30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold - <span style=\"color: #000080; font-weight: bold\">2</span>| f-score: <span style=\"color: #000080; font-weight: bold\">0.6751</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efb9e5041f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold - <span style=\"color: #000080; font-weight: bold\">3</span>| f-score: <span style=\"color: #000080; font-weight: bold\">0.6998</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efb48645fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold - <span style=\"color: #000080; font-weight: bold\">4</span>| f-score: <span style=\"color: #000080; font-weight: bold\">0.6921</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efac5517c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5)\n",
    "scores_own = []\n",
    "for i, (train_idx, test_idx) in enumerate(cv.split(X_own, y)):\n",
    "    X_train, y_train = X_own[train_idx], y[train_idx]\n",
    "    X_test, y_test = X_own[train_idx], y[train_idx]\n",
    "    model = LogisticRegression(C=100, max_iter=100, verbose=5, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = f1_score(y_test, model.predict(X_test), average='macro')\n",
    "    print(f\"Fold - {i}| f-score: {score:.4f}\")\n",
    "    scores_own.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold - <span style=\"color: #000080; font-weight: bold\">0</span>| f-score: <span style=\"color: #000080; font-weight: bold\">0.6762</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efb54fab2e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold - <span style=\"color: #000080; font-weight: bold\">1</span>| f-score: <span style=\"color: #000080; font-weight: bold\">0.6646</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efb4c5a5e20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold - <span style=\"color: #000080; font-weight: bold\">2</span>| f-score: <span style=\"color: #000080; font-weight: bold\">0.6589</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efb4865df40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold - <span style=\"color: #000080; font-weight: bold\">3</span>| f-score: <span style=\"color: #000080; font-weight: bold\">0.6731</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efb544deeb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold - <span style=\"color: #000080; font-weight: bold\">4</span>| f-score: <span style=\"color: #000080; font-weight: bold\">0.6746</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efb5149fe20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5)\n",
    "scores_rusvec = []\n",
    "for i, (train_idx, test_idx) in enumerate(cv.split(X_rusvec, y)):\n",
    "    X_train, y_train = X_rusvec[train_idx], y[train_idx]\n",
    "    X_test, y_test = X_rusvec[train_idx], y[train_idx]\n",
    "    model = LogisticRegression(C=100, max_iter=100, verbose=5, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = f1_score(y_test, model.predict(X_test), average='macro')\n",
    "    print(f\"Fold - {i}| f-score: {score:.4f}\")\n",
    "    scores_rusvec.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Our embeddings: <span style=\"color: #000080; font-weight: bold\">0.6877</span>+<span style=\"color: #000080; font-weight: bold\">-0.0082</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efb54fab9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Our embeddings: {np.mean(scores_own):.4f}+-{np.std(scores_own):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">RusVec embeddings: <span style=\"color: #000080; font-weight: bold\">0.6695</span>+<span style=\"color: #000080; font-weight: bold\">-0.0066</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efb54fabee0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"RusVec embeddings: {np.mean(scores_rusvec):.4f}+-{np.std(scores_rusvec):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание №2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учим SVD и NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD, NMF, PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_pipeline = Pipeline(steps=[\n",
    "    ('tf-idf', TfidfVectorizer(ngram_range=(1,3))),\n",
    "    ('svd', TruncatedSVD(n_components=200))\n",
    "])\n",
    "nmf_pipeline = Pipeline(steps=[\n",
    "    ('tf-idf', TfidfVectorizer(ngram_range=(1,3))),\n",
    "    ('nmf', NMF(n_components=200))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([\n",
    "    data['text_1'].apply(lambda x: normalize(tokenize(x))),\n",
    "    data['text_2'].apply(lambda x: normalize(tokenize(x)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tf-idf', TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                ('nmf', NMF(n_components=200))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_pipeline.fit(train_data)\n",
    "nmf_pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "генерим фичи(будем считать расстояния сразу, а не потом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e426d5db5a4f358168aa4e84870d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7227.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svd_distances = []\n",
    "nmf_distances = []\n",
    "w2v_own_distances = []\n",
    "w2v_rusvec_distances = []\n",
    "fasttext_distances = []\n",
    "for row in tqdm(data.itertuples(), total=len(data)):\n",
    "    s1 = svd_pipeline.transform([normalize(tokenize(row.text_1))])\n",
    "    s2 = svd_pipeline.transform([normalize(tokenize(row.text_2))])\n",
    "    svd_distances.append(cosine_similarity(s1, s2).ravel())\n",
    "    \n",
    "    n1 = nmf_pipeline.transform([normalize(tokenize(row.text_1))])\n",
    "    n2 = nmf_pipeline.transform([normalize(tokenize(row.text_2))])\n",
    "    nmf_distances.append(cosine_similarity(n1, n2).ravel())\n",
    "    \n",
    "    w1 = get_embedding(normalize(tokenize(row.text_1)), w2v, 300)\n",
    "    w2 = get_embedding(normalize(tokenize(row.text_2)), w2v, 300)\n",
    "    w2v_own_distances.append(cosine_similarity([w1], [w2]).ravel())\n",
    "    \n",
    "    r1 = get_embedding(\" \".join(normalize_mystem(row.text_1)), w2v_rusvec, 300)\n",
    "    r2 = get_embedding(\" \".join(normalize_mystem(row.text_2)), w2v_rusvec, 300)\n",
    "    w2v_rusvec_distances.append(cosine_similarity([w1], [w2]).ravel())\n",
    "    \n",
    "    f1 = get_embedding(normalize(tokenize(row.text_1)), fst, 300)\n",
    "    f2 = get_embedding(normalize(tokenize(row.text_2)), fst, 300)\n",
    "    fasttext_distances.append(cosine_similarity([f1], [f2]).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dist = pd.DataFrame({\n",
    "    'svd': map(lambda x: x[0], svd_distances),\n",
    "    'nmf': map(lambda x: x[0], nmf_distances),\n",
    "    'w2v_own': map(lambda x: x[0], w2v_own_distances),\n",
    "    'w2v_rusvec': map(lambda x: x[0], w2v_rusvec_distances),\n",
    "    'fasttest': map(lambda x: x[0], fasttext_distances),\n",
    "    'label': y\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_dist.loc[:, ['svd', 'nmf', 'w2v_own', 'w2v_rusvec', 'fasttest']].values\n",
    "y = data_dist['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold - <span style=\"color: #000080; font-weight: bold\">0</span>| f-score: <span style=\"color: #000080; font-weight: bold\">0.5803</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efb49b0c0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold - <span style=\"color: #000080; font-weight: bold\">1</span>| f-score: <span style=\"color: #000080; font-weight: bold\">0.5708</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efb49265b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold - <span style=\"color: #000080; font-weight: bold\">2</span>| f-score: <span style=\"color: #000080; font-weight: bold\">0.5671</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efb4b773e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold - <span style=\"color: #000080; font-weight: bold\">3</span>| f-score: <span style=\"color: #000080; font-weight: bold\">0.5939</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efdfeea5a00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold - <span style=\"color: #000080; font-weight: bold\">4</span>| f-score: <span style=\"color: #000080; font-weight: bold\">0.5962</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efb4b773e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5)\n",
    "scores = []\n",
    "for i, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[train_idx], y[train_idx]\n",
    "    model = LogisticRegression(C=100, max_iter=100, verbose=5, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = f1_score(y_test, model.predict(X_test), average='micro')\n",
    "    print(f\"Fold - {i}| f-score: {score:.4f}\")\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Scores for distfeatures: <span style=\"color: #000080; font-weight: bold\">0.5817</span>+<span style=\"color: #000080; font-weight: bold\">-0.0118</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efac5517be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Scores for distfeatures: {np.mean(scores):.4f}+-{np.std(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробовал крутить параметры у svd и nmf - без особого результата, значения метрик остаются примернов в таком же диапазоне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
