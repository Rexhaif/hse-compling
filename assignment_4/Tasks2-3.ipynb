{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text as skf\n",
    "import sklearn.metrics.pairwise as skd\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.metrics as skms\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?)\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                     comment  \\\n",
       "0                                                                                                                                                       Верблюдов-то за что? Дебилы, бл...\\n   \n",
       "1                                                                 Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\\n   \n",
       "2                                                                                                                                                                  Собаке - собачья смерть\\n   \n",
       "3  Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\\n   \n",
       "4                                                                  тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?)\\n   \n",
       "\n",
       "   toxic  \n",
       "0    1.0  \n",
       "1    1.0  \n",
       "2    1.0  \n",
       "3    1.0  \n",
       "4    1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    9586\n",
       "1.0    4826\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14412, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comment'] = data['comment'].str.replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data['comment'].tolist(), data['toxic'].values.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.4 s, sys: 1min 40s, total: 2min 25s\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec = skf.TfidfVectorizer(ngram_range=(1, 3), min_df=10)\n",
    "svd = TruncatedSVD(n_components=100, n_iter=100, random_state=42) \n",
    "# без нулей так без нулей\n",
    "X_vec = vec.fit_transform(X)\n",
    "X_vec = svd.fit_transform(X_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a - Посчитайте близость между 3 и 12666 текстами в датасете (labeled.csv из семинара) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16230719]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skd.cosine_similarity([X_vec[2]], [X_vec[12665]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### б - найдите 3 самых близких текста к тексту номер 43; выведите сами тексты и значения близостей, а не только индексы этих текстов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest(idx: int, k: int = 3):\n",
    "    sims = np.array(list(map(\n",
    "        lambda x: skd.cosine_similarity([x], [X_vec[idx]]), tqdm(X_vec)\n",
    "    ))).squeeze()\n",
    "    \n",
    "    nearest = np.argsort(sims, kind='heapsort')[-k-1:] ## search for k+1 neighbors to skip first as it is our vector\n",
    "    result = []\n",
    "    for n_idx in nearest[::-1][1:]: # to skip first result\n",
    "        result.append({'idx': n_idx, 'similarity': sims[n_idx], 'text': X[n_idx]})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22b4d0d8b484e95b9cc42e318d16ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14412.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>similarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570</td>\n",
       "      <td>0.669467</td>\n",
       "      <td>он, как любой психически здоровый человек Он и в существование психики не верит. Что ты на это скажешь, девственник?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3719</td>\n",
       "      <td>0.632034</td>\n",
       "      <td>Можно же совмещать:3Быть молодым, целеустремлённым, ленным, полным надежд глупцом:3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5727</td>\n",
       "      <td>0.624819</td>\n",
       "      <td>Рак ебучий, как же ты заебал, сука. СДОХНИ БЛЯДЬ И ПЕРЕСТАНЬ ТАСКАТЬ НА ФИГУРЧ ЗАЛЕТУХ!!1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx  similarity  \\\n",
       "0   570    0.669467   \n",
       "1  3719    0.632034   \n",
       "2  5727    0.624819   \n",
       "\n",
       "                                                                                                                    text  \n",
       "0  он, как любой психически здоровый человек Он и в существование психики не верит. Что ты на это скажешь, девственник?   \n",
       "1                                   Можно же совмещать:3Быть молодым, целеустремлённым, ленным, полным надежд глупцом:3   \n",
       "2                             Рак ебучий, как же ты заебал, сука. СДОХНИ БЛЯДЬ И ПЕРЕСТАНЬ ТАСКАТЬ НА ФИГУРЧ ЗАЛЕТУХ!!1   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(k_nearest(42, k=3)) # dataframe for visualization proposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = skm.train_test_split(np.array(X), y, test_size=0.2, random_state=1993)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Первая модель - Naive Bayes + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = Pipeline([\n",
    "    (\n",
    "        \"vec\",\n",
    "        skf.CountVectorizer(\n",
    "            lowercase=True,\n",
    "            max_df=0.9, \n",
    "            max_features=10000,\n",
    "            min_df=2,\n",
    "            ngram_range=(1,1),\n",
    "            stop_words=None\n",
    "        )\n",
    "    ),\n",
    "    (\n",
    "        \"clf\",\n",
    "        MultinomialNB(alpha=0.9, fit_prior=False)\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.9,\n",
       "                                 max_features=10000, min_df=2,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=0.9, class_prior=None, fit_prior=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.89      0.89      1926\n",
      "         1.0       0.78      0.80      0.79       957\n",
      "\n",
      "    accuracy                           0.86      2883\n",
      "   macro avg       0.84      0.84      0.84      2883\n",
      "weighted avg       0.86      0.86      0.86      2883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(skms.classification_report(y_test, nb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вторая модель - LogReg + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Pipeline([\n",
    "    (\n",
    "        'vec',\n",
    "        skf.TfidfVectorizer(\n",
    "            stop_words = None,\n",
    "            ngram_range = (1, 1),\n",
    "            min_df = 1,\n",
    "            max_df = 1.0,\n",
    "            max_features = 75000,\n",
    "            lowercase = True\n",
    "        )\n",
    "    ),\n",
    "    (\n",
    "        'clf',\n",
    "        LogisticRegression(\n",
    "            C = 100.0,\n",
    "            penalty = 'l2',\n",
    "            fit_intercept = True\n",
    "        )\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=75000,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=100.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.94      0.90      1926\n",
      "         1.0       0.86      0.71      0.78       957\n",
      "\n",
      "    accuracy                           0.86      2883\n",
      "   macro avg       0.86      0.83      0.84      2883\n",
      "weighted avg       0.86      0.86      0.86      2883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(skms.classification_report(y_test, logreg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводим топ-10 самых токсичных текстов по версии каждой из моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by probability of toxic class\n",
    "top_nb = np.argsort(nb.predict_proba(X)[:, 1])[-10:]\n",
    "top_logreg = np.argsort(logreg.predict_proba(X)[:, 1])[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из приведенных текстов видно, что модели на основе CountVectorizer + Naive Bayes требуется значительно большее количество токсичных слов для того чтобы присвоить тексту класс токсичности(или высокой вероятности оной). В то же время модель на основе TF-IDF + LogReg хорошо справляетс и с маленькими текстами. Субъективно  - можно заметить что тексты 3 и 4 из модели NB не являются в действительности токсичными, однако содержат очень много слов(навальный, соловьев, дота и т.д), вероятнее всего употребляющихся в токсичных контекстах в корпусе, видимо поэтому они и были промаркированы как токсичные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================[0]==================================================\n",
      "--------[NB-scored text]--------\n",
      "эта мразота терроризирует треды более двух лет, вниманиеблядствует и потешается над анонами. Пруфы того, что в треды срет один и тот же человек, потешается над анонами и злоупотребляет бездействием модераторов . эти вебмки сделаны им Его тред, куда он срал своими скримерами поискав по метадате, можно найти десятки тредов, куда он срал своими скримерами, по 15-20 штук в треде. Пруфы засирания тредов , к примеру. Поиском можно найти намного больше 2 вебм начало 1:19 0:49 и 3:57 3:16 1:23 Пруфы многократных жалоб от анонов на деятельность этого серуна ПРИМИТЕ МЕРЫ БЛЯДЬ!!!!!! \n",
      "------[logreg-scored text]------\n",
      "Какие же хохлы революционеры, пиздец просто \n",
      "==================================================[1]==================================================\n",
      "--------[NB-scored text]--------\n",
      "именно так. смотрю на тебя, стаса, вестника дури и считаю ебланами. Твоё дело. Это вполне логичная реакция буржуя на тот факт, что его собрались раскулачивать. мотрю на всех царей(!) ссср и считаю ебланами, в том числе их ебланскую жадность, жестокость и жажду власти. А вот тут ты запизделся. СССР сделал из России сверхгосударство в сильнейшим образованием, мощнейшей экономикой, огромной военной мощью и кучей инновационных технологий. Можно сколько угодно рассуждать про мораль и этику, но нельзя отрицать статистику. С ней нельзя спорить. Что мы имеем? Продолжительность жизни - выросла в 2 раза. Образование - с 10 до 90 населения. Прирост населения - 40кк. Уровень жизни - растёт. Электрификация - всего государства. Нельзя спорить с цифрами. Посмотри на картинки. Это действительно итог работы тиранов и царе? Это итог работы душегубов и руссофобов? Или же что, статистику подменили и в РИ люди не были голодными, холодными, необразованными и без света? Может в РИ технологии какие изобретали, а? тебя ктото угнетает? Капиталисты. Все и сразу. Всё просто. сори, но ты просто тупой. все нынешние коммунисты просто ебаные страусы, если я засунул голову в песок и не вижу фактов - это значит, что их нет Каких фактов. Вот у меня на картинках статистические факты. Ты мне говоришь про голод и репрессии, а я говорю тебе что срок жизни человека вырос с 30 лет до 70, а население выросло с 170кк до 214кк. Где репрессии? Где голод? Почему они противоречат статистике? растрелянных не было Было. Но мало и по делу. А что? Нельзя расстреливать преступников? Почему? не понравился коммуняке - ты недочеловек, расстрелять. Не хочу тебя расстраивать, но коммунизм это диктатура пролетариата. То есть решение о расстреле принимает не один человек, а всё государство, просто подписывает его ответственный. А если ты не нравишься целому государству - чтож, сам виноват, наверняка творил хуйню. Я вот хуйню бы творить не стал и если надо, то изменился бы ради общественного блага. Поэтому бы меня не расстреляли, я же не преступник как те кого расстреляли в СССР. то, что дяди в интернете с псевдофактами сказали, что коммунисты были святыми Никто не говорит что они были святыми. Более того - на всех каналах что я посоветовал во многом критикуют СССР. Проблема в том, что критика СССР из вне, то есть не из стана левых сил, всегда сводится к мемам уровня Катыни и Голодомора, которые являются чистейшей ложью и клеветой на весь левый корпус. почитай про пакт молотова-рибентропа Было такое, да. Тут всё дело было в том, что в глазах коммуниста разницы между буржуем нацистом и буржуем империалистом - нет. Поэтому ожидания коммунистов были что вся грязь себя перехуярит и мы восстановим их государства под коммунистическим флагом. Го Хитлур был ебанутым и решил воевать со всем миром. захват польши Не существует такого факта как ЗАХВАТ в мире коммунизма. Коммунизм подразумевает интернационал и мировое государство. Нельзя захватить чужую территорию потому, что все территории принадлежат коммунизму. катынь Это мем и фейк. Поляки хуярили своих же в погоне за властью. массовое переселение целых народов внутри страны Что плохого в распределение производственных сил? Это банальная оптимизация. гулаг Что плохого в тюрьмах для преступников в отдалении? для тебя и твоих кумиров только одна проблема в нынешнем мире Наверно поэтому с каждым годом коммунистов всё больше и больше, а так же реальной оппозицией которая борется за права людей в России являются коммунисты, да? смешно то, что каждый из вас адептов коммунизма ерзает на капиталистическом кукане, приговаривая какие у меня охуенные идеи есть для этого кукана, вот бы он был красным . Компьютеры теперь капиталистическая идея, лол? Щта? Ты вообще там поехал чтоли? Еще раз - коммунизм это не сидеть в тёмном сыром подвале и жрать говяжий анус, коммунизм это прогресс и справедливость. Первые ЭВМ были изобретены в СССР. СССР сделал огромный вклад в развитие ЭВМ технологий и изобрёл гениальную троичную логику. СССР делал канкуляторы и телевизеры, делал радивы и телефоны. Ты совсем там ебобо? Речь коммуниста была про то что нехуй в игрушки играть, а пора использовать ЭВМ для работы, не более. ты в упор не видишь, хуле тебе объяснять Не вижу. Скинь шебмки.\n",
      "------[logreg-scored text]------\n",
      "мандан против хохлов? \n",
      "==================================================[2]==================================================\n",
      "--------[NB-scored text]--------\n",
      "Сука, ты ему про аномалии, а он тебе ПРО ХАБАР! ПРИЧЕМ ТУТ РЕЗАНЬЕ ПОЛОВЫХ ОРГАНОВ И ИЗНАСИЛОВАНИЯ, А ДЕБИЧ? ПРИРОДА ДАЛА МУЖЧИНАМ СИЛУ И МОЗГИ, ЧЕГО ЖЕНЩИНЫ СМОГУТ ПРИОБРЕСТИ ТОЛЬКО ЧЕРЕЗ ГИГАНТСКОЕ УПОРСТВО . Здесь речь не о дискриминации, А О БАНАЛЬНОМ ФАКТЕ ! Ну а кукареканье о равенстве прав - всего лишь КУКАРЕКАНЬЯ , я только представлю себе бабу металлурга и уже смешно становится, нет у них способностей к мужским профессиями - НУ И НЕХУЙ ТУДА ПРОСИТЬСЯ . Пускай есть готовят, за больными ухаживают, одежду шьют, картины рисуют и всё остальное, чем они обычно занимаются, НО РАВЕНСТВА В ПРАВАХ, ПОМИМО РАВЕНСТВА ЮРИДИЧЕСКИХ - ЭТО ПРОСТО АБСУРД. Если эта Фелмке Халсема топит за равенство, ТАК ПУСКАЙ БЕРЕТ АВТОМАТ В РУКИ И ПИЗДУЕТ ЗАЩИЩАТЬ СВОЮ СТРАНУ. ДЕЛАЕТ БЛЯДЬ МАРШ-БРОСКИ КАЖДЫЙ ДЕНЬ, РОЕТ ОКОПЫ, ПИЗДИТСЯ, УЧИТСЯ СТРЕЛЯТЬ, КОЛОТЬ ЧЕЛОВЕКА В РУКОПАШНУЮ И БРОСАТЬСЯ НА АМБРАЗУРЫ, ДОКАЗЫВАЯ ЧТО ОНА НИЧЕМ НЕ ХУЖЕ. Но нет, она же способна только пиздеть и ущемлять мужиков в их законных правах, нарушая стойкую систему и порядок. \n",
      "------[logreg-scored text]------\n",
      "Какие блять передергивания? Ты дебил блять зашел на шок-доску и удивляешься что над тобой издеваются. Тут нет твоих друзей, рачье тупорылое, тут тебя все ненавидят. Как же печет от таких необучаемых ебланов. Ты ковбой, твою жену ебут где-то нахуй, а дети гибнут на Украине. Понял, быдло ты ебаное? \n",
      "==================================================[3]==================================================\n",
      "--------[NB-scored text]--------\n",
      "navalny Максим Галкин maxgalkinru задал мне вопрос. С удовольствием отвечаю: Максим, спасибо за то, что подняли такую важную проблему. Однако, согласиться с Вами не могу. Вы подаёте дело так, как будто Владимир Соловьёв - просто звезда шоу-бизнеса, наподобие американской Опры. Зарабатывает много, значит может покупать себе дома где угодно. Это не так. Соловьев - государственный пропагандист на государственном телевидении. Сейчас он везде и не вылезает с экрана не потому, что талантлив, а потому что в стране ТВ-монополия государства. Соловьёв готов врать больше других, вот его и держат на экране. Была бы реальная конкуренция между ток-шоу и их телеведущими, Соловьёв был бы там, где ему и место - третьесортным радиоведущим. Каким он собственно и был до того, как всех настоящих звезд ток-шоу с нашего телевидения не выгнали, а их программы не закрыли по соображениям цензуры. Максим, вы говорите о рейтингах и прибылях, которые Соловьёв приносит каналу Россия-1 , а я смотрю в таблицу бюджета нашей страны и вижу, что Россия-1 глубоко убыточна. Ежегодно получает бюджетную дотацию. 24,6 миллиарда рублей за прошлый год. 24 МИЛЛИАРДА, Максим. Этого бы хватило на то, чтобы оплатить операции всем больным детям в стране. Но ушло это на гонорары всяким соловьёвым, а потом превратилось в виллы на итальянском озере Комо. Так что это не Соловьёв приносит. А все мы - налогоплательщики - (и Вы тоже, Максим) приносим деньги ему в карман. И я не хочу оплачивать роскошную итальянскую жизнь этого лжеца, лицемера и мерзавца. Тут нет никакой ненависти к богатым, никакого большивизма. Только здравый смысл. Видео взято с телеканала Дождь , логотип обрезан не по злому умыслу, а потому что его отрезал инстаграм, делая ролик квадратным. \n",
      "------[logreg-scored text]------\n",
      "Пидорашек выселить, а не хохлов Ты сам себе противоречишь, дурачок. \n",
      "==================================================[4]==================================================\n",
      "--------[NB-scored text]--------\n",
      "Стрим 09.02.2019, некоторые интересные моменты 1. Начало стрима 5.00 2. Я куколка 3. Встаёт, показывает лук 7.10 4. Пыталась поиграть в доту, но не смогла. Не понравилось. 7.48 5. Поддерживает новые толерантные игры в которых есть персонажи геи 9.20 6. Вчера не ходила в качалку. 7. Про гендеры, их больше чем два. Карина это поддерживает. 12.35 8. У меня нет друзей чтобы играть в командные игры 15.10 9. Скоро останутся только вк и ок 18.00 10. Про фильм Девочка , хочет посмотреть его 19.25 11. Включила роли по фильму Алита 23.00-27.42 12. Обнимашки от Карины (реакция на донат) 30.15 13. Про Корею, фильм В лучах солнца , политику, Китай 37.40 14. Думает сделать как-нибудь макияж на стриме 38.15 15. Про Париж, думает куда бы хотела сходить 41.40 16. Билет в кино стоит 15-20 евро 45.20 17. Показывает платье во весь рост 46.05 18. Говорит по японски 48.55 19. Карина очень давно отбеливала зубы, но особого результата не было 50.00 20. История про то как ходила в 24 часовой магазин, чуть не сбила машина. Потом за это отругала мама 54.35 21. До меня никто не доёбывался, кроме фанатов 58.50 22. Думала купить травмат 59.45 23. Не может покупать дорогие вещи, какой-то барьер 1.00.40 24. Про бренды, удобную обувь 1.01.20 25. Встала, показывает свои розовые кросы Вансы 1.04.35 26. Самая дорога вещь которую купила - пуховик зеленый за 150-200 баксов 1.05.30 27. Как ты ухаживаешь за волосами? 1.08.55 28. Встала, ушла за кроссами Buffalo, принесла и надела на ногу 1.09.50 29. Про доставку еды в Леньяно 1.12.40 30. Про такси и поездку в нём с итпедиа 1.15.00 31. Вопрос про стримы 2015-2016. Карина не ностальгирует по ним 1.22.00 32. Хейт-донат про межнациональные браки. Карина поддерживает таки отношения 1.22.58 33. Про коммунизм 1.30.25 34. Проходила психологический тест, Карине в душе 68 лет 1.41.04 35. Возможно у меня сбитая биологическая прошивка (про то что не хочет детей заводить) 1.44.00 36. Про садик 1.50.40 37. Про школу и туалеты 1.52.00 38. Про игру метро 1.58.55 39. Игры надоели 2.01.00 40. Включила ролик со штукой которую хотела бы себе, для записи музыки, опи-1. Смотрит сколько эта штука стоит. 2.03.47 41. Включила видео с Алитой 1.08.00-1.10.05 42. Говорит что новый микрофон нравится больше (он изолирует звук, подавляет шумы) 2.12.00 43. Хочет поиграть на следующем стриме в Hearthstone 2.14.25 44. Ест червячка-желейку 2.21.30 45. Про аниме 2.22.50 46. Включила OST из аниме GTO (Great Teacher Onizuka) Opening 2 2.24.00 47. Кариан про аниме Эльфийская песня . Плакала когда смотрела. Это шедевр. 2.31.30 48. Карина задумалась. 2.37.00 49. Говорит по итальянски 50. Думает что желудок стал ещё меньше после болезни 2.48.00 51. Играет трек который постоянно включают в качалке куда ходит Карина 2.49.30 52. Подготовка к стриму уходит 40 минут (косметика и т.д.) 2.52.40 53. Про Ларина 2.54.00 54. Заменила бы себе тело на кибертело 2.57.50 55. Про вред наркотиков 3.00.00 56. Про бухло, курево, травку 3.08.00 57. Нашла трек со старого стрима, который просили найти в донате KING PLAGUE - Ave Plague 2.25.00\n",
      "------[logreg-scored text]------\n",
      "Блядь абу нахуй ссылай этих дегенератов в фаг, всем похуй на их шлюх \n",
      "==================================================[5]==================================================\n",
      "--------[NB-scored text]--------\n",
      "Стас, никому, кроме тебя и армии твоих подсосов(которые представляют собой типичный дегенеративный биомусор, ведущийся на любые скандалы-интриги), твои ролики нахуй не нужны. Серьёзно, ты сделал новости с целью показать, что такое говно может делать любой, а аудитория осталась на том же уровне, ведь людям извне ты не интересен. Да ещё и просит не подписываться, чтобы такую-то годноту ложкой хлебать подольше. Ты обосрался, стал посмешищем для абсолютно всех ютуберов, которые не являются полными ебланами. Тот же Хованский не ссыт тебе на ебало только потому, что ты вертишься с ним в одной компании, иногда даже лично пересекаетесь. Приятно было слышать, как он говорил, что отстреливался бы от таких, как ты, из огнестрела, стараясь забрать с собой побольше коммунистов, когда они придут его оаскулачиапть? Он открыто хуесосил людей и за меньшие грехи. Сложи 2 и 2, как он к тебе относится на самом деле. После чего ты сделал ещё более смешной ролик, где истеришь как побитая шлюха во время ПМС. Я ПОДЕБИЛ, А ЕСЛИ ВЫ НЕ ПОНЯЛИ ЭТОГО, ТО ВЫ ТУПЫЕ . Ты мог хотя бы сам его посмотреть перед заливом? Мне даже рофлить над тобой расхотелось, из смешного дегенерата, ты стал жалким дурачком. Это как смеятся над роликами, где контуженные ветераны пытаются ходить под клубную музыку. Над неполноценными смеятся плохо, даже стыдно стало. Я не утрирую. Просто посмотри на себя, Стас. Ну правда. Банишь людей в группе за лвйки и одно упоминание стрима. Ты делаешь всё, в чём самый отбитый и дегенеративный либераст обвиняет совок и сверкаешь разорванным очком. Никто тебя несправедливо не обсирал. Что на стриме по поводу дат, ну ты же сам проебался. На подкасте сообщил, что не будешь стримить. Если ты не был уверен, то зачем это говорить? А если был, почему не сообщил Маргиналу сразу же? Твоё слово в целом не стоит нихуя. Обещаешь не банить-куча удалённых комментов. Обещаешь стрим-не идёшь. Обещаешь что-то ещё, всегда проёбываешься, всё чаще на нарушение обещания тебе нужно в районе секунды-дня. Стоит ли удивлятся, что тебе за это прилетело? Когда то должно было. Ты сам срёшь себе в штаны, не злись, когда на это указывают пальцем.\n",
      "------[logreg-scored text]------\n",
      "Ты охуела, мразь? Я же тебя найду блять. Гридин не свинья, ты понял, петух? НЕ СМЕЙ НАЗЫВАТЬ КУЗЬМУ СВИНЬЕЙ ДЭБИЛ ГОРОХОВЫЙ! \n",
      "==================================================[6]==================================================\n",
      "--------[NB-scored text]--------\n",
      "дерейлы тредов за счёт постоянных провокаций, неуместных форсов, чатиков и оскорблений других анонов в нём также приведут к бану. 7 постов гомофорса на 100, вот уж проблема и засирание треда Гомофорс - это, прежде всего, форс. Он прикрывается традицией и местными обычаями, а его апологеты утверждают, что форс смешной и без него уже нельзя. Никто не называет его смешным, никто не говорит, что без него нельзя. Всех в конец заебало обсуждение одних тем и анон так развлекается. Последние свитки вышли в 11м, тесо и легенды никто не играл, а некоторые особо одарённые и вовсе считают никаноном. А гомофорс это просто общение в треде обо всём без чёткой тематики. Однако если это форсится без меры 3 года подряд и просачивается в другие треды, раздражая анонов, то это должно пресекаться. просачивается в другие треды Вот и бань тех кто просачивается без меры Где ты был полтора года назад, когда на доске висело 35 вопросов тредов? Вот это было без меры, но теперь даже гринтекстовых срачей почти нет. Теперь приходится вставлять гомофорс в обычные посты, но даже их трут: А это и вовсе ответ на вопрос о гомофорсере, который был ни с хуя потёрт 1257469 Он тут не пролазит, это его доска. Гомофорс - неотъемлемая часть тесача, существующая уже два с половиной года. А вот как сюда пролазят гомохейтерки вроде тебя - это вопрос. Системность следования правилам раздела, отсутствие избирательного отношения или фаворитизма по отношению к тому или иному форсу, - Ага, поэтому меня забанили за гомофорс вчера, а не за данмерских шлюх неделю назад. залог стабильного постинга на честной доске. Будто бы гомофорс мешает общению. Опять же, 35 тредов полных гринтекста и простыней шизиков. И никто никому не мешал. Причина по которой на него раньше закрывали глаза это были местные юморески. Один из предыдущих мочеров назвал это традицией. Не помню ни одного случая, когда банили за посты, приведённые выше, всегда за гринтекст. Но гринтекст прекратился - начались баны за любое упоминание гомофорса. Поэтому аноны, упорствующие в гомофорсе, могут и будут забанены на средние сроки - неделю или две. Особо упорствующие могут попасть под пермач. Вот и всё. Вот только с хуя ли моча мешает общению анонов. Ни один из недавних постов с гомофорсом не получил продолжения в виде однострочного срача, с хуя ли их потёрли? Чем плох этот пост? Нет 100 правдивой версии замерзания Атморы, а хедканон у каждого свой, как завещал мишаня. Мой хедканон делает моче ниприятно? Когда норды сидели под сапогом альдмеров великой Альтморы всё было нормально. В Сиродиле джунгли, на Альтморе тёплый климат, а весь Скайрим был покрыт лесами. Всё дело в том, что альдмеры проводя ритуалы, славящие их богов, создавали много тепла своими жаркими телами, мужчины альдмеры трудились не покладая удов, чтобы поддерживать благоприятный климат, но норды были холодны и безнравственны. Мужчинам они предпочитали женщин, а такая порочная, грязная любовь не сравнится с жаром пылких альдмерских мужчин, сплетаясь образующих столько тепла, что хватает на весь континент. Когда пришла власть нордов и Обманщика, все альдмеры были убиты, а великие традиции мужской любви попали под запрет, и некогда вечнозелёная Альтмора начала превращаться в ледяную пустошь Атмору. В итоге норды сами были вынуждены бежать в Скайрим, где они вырезали фалмеров, из-за чего половина Скайрима сейчас непригодна для жизни из-за холода. Та же участь постигла и айлейдов, и вместо влажных джунглей в Сиродиле теперь простые леса. Раньше гринтекстовый срач был развёрнутый, с подробным описанием того, кто кому куда и в каком количестве суёт. И это не банилось. Может моче просто нравились эти гомоэротические рассказы, и он на нас сердится, из-за того что они перестали быть оригинальными, а потом от них и вовсе отказались. Ты скажи нам, думаю это можно исправить.\n",
      "------[logreg-scored text]------\n",
      "ИДИ НАХУЙ, СУКА, ЗАВАЛИ ЕБАЛО, БЛЯТЬ \n",
      "==================================================[7]==================================================\n",
      "--------[NB-scored text]--------\n",
      "А нахуй ты тут персональный чатик устроил, дегенерат? Или ты сейчас каждому работяге, который зайдет в твой обоссаный тред будешь бежать доказывать в чем он не прав и как нужно сделать шоб было всё нормально ? Проблема травлятредов была озвучена ещё задолго до того, как ты и тебе подобные, кукарекающие про школьников, срыватели покровов засунул на этот сайт свой немытый ебальник. Правда для этого люди не разводили шитпостинг на овер 100 постов с переливанием из пустого в порожнее. b для этого подходит идеально - вот там со своими братьями по разуму и разводи драму, хоть на несколько тредов. Я кончил и закурил, можешь теперь маршировать нахуй. \n",
      "------[logreg-scored text]------\n",
      "мимо хикка Ты не хикка, ты чмо с отклонениями в психике. Поссал на тебя. \n",
      "==================================================[8]==================================================\n",
      "--------[NB-scored text]--------\n",
      "Очевидно, что топтать дворников и чем там ещё федоровичи по всей стране занимались- это просто другой уровень деятельности Вот и попался куколд-воевака. А гонору сколько было, да мы на дунбусее, да я в грозном двери настежь - давай говно на разы. Когда твою сестру будут насиловать черенком от веника три дворника, то ты будешь просто играть в Подземелья и Драконы и делать вид что ничего не происходит. А не, как Джимми Нейтрон напряжёшь мозги и будешь искать РЕЛЕВАНТНОЕ решение проблемы, пока сестричке, с венком ромашек на голове, раздирают дырочку. Ссали тебе в рот всем кондопогом, чека-нацианалистъ. Твои маняврирования от вопросов точно такое же тухлое пиздабольство как и на стремах жирного, можешь в гости записатся, если достаточно всратый для их патоков. Ах, да, а хули ты у мамы под юбкой, а не спасаешь наших новиопов в трусках от злых фашистов? За пять лет так и не собрался? Давай реще, чучело. \n",
      "------[logreg-scored text]------\n",
      "Нахуй иди чмо ебаное, рот твой ебал. Говна поешь, быдло \n",
      "==================================================[9]==================================================\n",
      "--------[NB-scored text]--------\n",
      "украинскими фашистами Изобретение украинского фашизма дьявольский триумф политтехнологов, которым удалось создать миф о бандеровцах , карателях и правосеках и внушить его власти и пресловутым 96 населения посредством телевидения. На весь 2014 год Россия, включая президента Путина, переехала жить в телевизор, в бесконечный сериал, в параллельную реальность, где по Киеву маршировали фашисты, каратели сбивали малайзийский боинг и распинали мальчика в Славянске, а Запад спонсировал Майдан, планировал принять Украину в НАТО и разместить корабли Шестого флота в Севастополе. Характерно использование российской пропагандой образа фашизма как синонима абсолютного, финального, зла, окончательного расчеловечивания противника. Фашизм в российском дискурсе обладает универсальной ценностью Другого, вся новейшая российская идентичность построена на идеологеме победы над нацизмом. Происходит онтологизация конфликта с Украиной как борьбы абсолютного добра с абсолютным злом. Война России в Украине пример чистого негативизма, основанного на чувстве собственной ущербности, компенсация комплекса неполноценности элиты по отношению к Западу и населения по отношению к обстоятельствам собственной жизни. Власть не может изменить роль России на международной арене при помощи мягкой силы , качественного экономического роста, добиться уважения и признания партнеров. Подавляющее большинство населения, запертое в рамках восстановленной Путиным сословной системы, также не в силах выйти за пределы государственного патернализма (по сути, сословного рабства) и социального паразитизма, синдрома выученной беспомощности. Символической компенсацией стало создание вымышленного врага в лице Украины и вымышленных побед аннексии Крыма и создания пиратских республик Донецка и Луганска. Но по сути Крымнаш и фактическое отторжение Юго-Востока Украины стали маршем проигравших . \n",
      "------[logreg-scored text]------\n",
      "Ебать вы тупые дебилы, ой блять \n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "for i, (text_nb, text_logreg) in enumerate(zip(X[top_nb], X[top_logreg])):\n",
    "    print((\"=\"*50) + f\"[{i}]\" + (\"=\"*50))\n",
    "    print(\"--------[NB-scored text]--------\")\n",
    "    print(text_nb)\n",
    "    print(\"------[logreg-scored text]------\")\n",
    "    print(text_logreg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
